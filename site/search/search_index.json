{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This is where I store all of my projects that I'm working on. </p> <p>DL Models</p>"},{"location":"DL-models/","title":"DL Models","text":""},{"location":"DL-models/#general","title":"General","text":""},{"location":"DL-models/#performance-metrics","title":"Performance Metrics","text":""},{"location":"DL-models/#models","title":"Models","text":""},{"location":"DL-models/#yolo","title":"YOLO","text":""},{"location":"DL-models/#retinanet","title":"RetinaNet","text":""},{"location":"DL-models/#abstract","title":"Abstract","text":"<ul> <li>Paper compared performance to YOLOv2 which it outperformed (and also outperformed Faster R-CNN)</li> <li>Dense sampling algorithms have always been trailing the accuracy of two-stage detectors until this paper</li> <li>They discovered that the extreme foreground-background class imbalance encountered during training of dense detectors is central cause </li> <li>Added a new loss function that down-weights the loss assigned to well-classified examples </li> <li>Focuses training on hard examples and prevents the vast number of easy negatives from overwhelming the detector during training </li> <li>RetinaNet matches the speed of one-stage detectors and surpasses the accuracy of two-stage detectors (in 2018)</li> </ul>"},{"location":"DL-models/#important-takeaways","title":"Important Takeaways","text":"<ul> <li>One-stage algorithms (YOLO) are faster than R-CNN</li> <li>RetinaNet matches the two-stage performance of Faster R-CNN (and FPN, Mask R-CNN) </li> <li>Does this by identifying class imbalance during training as the main obstacle and proposes a new loss function </li> <li>Loss function is a \"dynamically scaled cross entropy loss\" where the scaling factor decays to zero as confidence in the correct class increases </li> <li>This scaling factor can automatically down-weight the contribution of easy examples during training and rapidly focus the model on hard examples </li> <li>RetinaNet similar to RPN, SSD, FPN</li> <li>Emphasis that the results are due to loss function and not novel architecture </li> <li>Class imbalance: the loss due to frequent class can dominate total loss and cause instability during training</li> <li>At the beginning they set the probability of the rare class to be low so that the model expects it to be rare</li> <li>Uses the feature pyramid network (FPN) as backbone of RetinaNet</li> <li>Each level of pyramid can detect objects of a different scale </li> <li>Built FPN on top of ResNet architecture </li> <li>we only decode box predictions from at most 1k top-scoring predictions per FPN level, after thresholding detector confidence at 0.05</li> <li>The top predictions from all levels are merged and non-maximum suppression with a threshold of 0.5 is applied to yield the final detections</li> <li>Uses SGD (stochastic gradient descent)</li> <li>One of the most important design factors in a one-stage detecton system is how densely it covers the space of possible image boxes</li> <li>Used 3 scales and 3 aspect ratios per location</li> <li>Increasing beyond 6-9 anchors did not show further gains</li> </ul>"},{"location":"DL-models/#code","title":"Code","text":"<ul> <li>FB code: https://github.com/facebookresearch/detectron2 </li> <li>Above link updated from detectron to detectron 2, so more up to date than paper </li> <li>Detectron2 includes the retinanet model </li> <li>Info on detectron2: https://ai.meta.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/</li> </ul>"}]}